- num_prompts: 1
  prompt_length: 102400
  output_length: 2048
  request_rate: "inf"
  model: "nvidia/Llama-3.3-70B-Instruct-FP8"
  backend: "openai"
  base_url: "http://138.197.252.210:80"
  endpoint: "/v1/completions"

- num_prompts: 2
  prompt_length: 102400
  output_length: 2048
  request_rate: "inf"
  model: "nvidia/Llama-3.3-70B-Instruct-FP8"
  backend: "openai"
  base_url: "http://138.197.252.210:80"
  endpoint: "/v1/completions"

- num_prompts: 4
  prompt_length: 102400
  output_length: 2048
  request_rate: "inf"
  model: "nvidia/Llama-3.3-70B-Instruct-FP8"
  backend: "openai"
  base_url: "http://138.197.252.210:80"
  endpoint: "/v1/completions"

- num_prompts: 8
  prompt_length: 102400
  output_length: 2048
  request_rate: "inf"
  model: "nvidia/Llama-3.3-70B-Instruct-FP8"
  backend: "openai"
  base_url: "http://138.197.252.210:80"
  endpoint: "/v1/completions"

- num_prompts: 16
  prompt_length: 102400
  output_length: 2048
  request_rate: "inf"
  model: "nvidia/Llama-3.3-70B-Instruct-FP8"
  backend: "openai"
  base_url: "http://138.197.252.210:80"
  endpoint: "/v1/completions"

- num_prompts: 20
  prompt_length: 102400
  output_length: 2048
  request_rate: "inf"
  model: "nvidia/Llama-3.3-70B-Instruct-FP8"
  backend: "openai"
  base_url: "http://138.197.252.210:80"
  endpoint: "/v1/completions"

- num_prompts: 32
  prompt_length: 102400
  output_length: 2048
  request_rate: "inf"
  model: "nvidia/Llama-3.3-70B-Instruct-FP8"
  backend: "openai"
  base_url: "http://138.197.252.210:80"
  endpoint: "/v1/completions"

- num_prompts: 64
  prompt_length: 102400
  output_length: 2048
  request_rate: "inf"
  model: "nvidia/Llama-3.3-70B-Instruct-FP8"
  backend: "openai"
  base_url: "http://138.197.252.210:80"
  endpoint: "/v1/completions"




