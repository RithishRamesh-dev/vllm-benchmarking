- concurrency: 2
  num_prompts: 20
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 2
  num_prompts: 20
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 4
  num_prompts: 40
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 4
  num_prompts: 40
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 5
  num_prompts: 50
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 5
  num_prompts: 50
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 6
  num_prompts: 64
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 6
  num_prompts: 64
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 8
  num_prompts: 80
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 8
  num_prompts: 80
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 10
  num_prompts: 100
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 10
  num_prompts: 100
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 16
  num_prompts: 160
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http:/134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 16
  num_prompts: 160
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 32
  num_prompts: 320
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 32
  num_prompts: 320
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "dmistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 50
  num_prompts: 500
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"

- concurrency: 50
  num_prompts: 500
  prompt_length: 5600
  output_length: 140
  request_rate: "inf"
  model: "mistralai/Mistral-Small-24B-Instruct-2501"
  backend: "openai"
  base_url: "http://134.199.206.182:8000"
  endpoint: "/v1/completions"




